{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "data=pd.read_excel('Input_Path') \n",
    "\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "corpus=[]\n",
    "\n",
    "for index,row in data.iterrows():\n",
    "    corpus.append(row['Comments']) \n",
    "    \n",
    "\n",
    "data['Comments'] = data['Comments'].astype(\"str\")\n",
    "data['Comments'] = data['Comments'].str.lower()\n",
    "data['Comments'] = data['Comments'].str.replace(\".\",\"\")\n",
    "data['Comments'] = data['Comments'].str.replace(\",\",\"\")\n",
    "data['Comments'] = data['Comments'].str.replace(\"?\",\"\")\n",
    "data['Comments'] = data['Comments'].str.replace(\"/\",\"\")\n",
    "data['Comments'] = data['Comments'].str.replace(\"-\",\"\")\n",
    "data['Comments'] = data['Comments'].str.replace(\":\",\"\")\n",
    "data['Comments'] = data['Comments'].str.replace(\"!\",\"\")\n",
    "data['Comments'] = data['Comments'].str.replace(\"&\",\"\")\n",
    "data['Comments'] = data['Comments'].str.replace(\"(\",\"\")\n",
    "data['Comments'] = data['Comments'].str.replace(\")\",\"\")\n",
    "\n",
    "\n",
    "data['Comments'] = data['Comments'].apply(nltk.word_tokenize)\n",
    "\n",
    "for i in range(0,134):\n",
    "    for word in data['Comments'][i]:\n",
    "        if word in stopwords:\n",
    "            data['Comments'][i].remove(word)\n",
    "\n",
    "            \n",
    "data['Comments'] = data['Comments'].apply(', '.join)\n",
    "data['Comments'] = data['Comments'].str.replace(\",\",\"\")\n",
    "\n",
    "idea=data['Comments'] #Selecting the first column that has text. \n",
    "\n",
    "# corpus=[]\n",
    "# for i in data[\"Resolution\"]:\n",
    "#     corpus.append(i) \n",
    "#Converting the column of data from excel sheet into a list of documents, where each document corresponds to a group of sentences.\n",
    "#Count Vectoriser then tidf transformer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(idea.values.astype('U')) #ERROR AFTER EXECUTING THESE #LINES\n",
    "\n",
    "#vectorizer.get_feature_names()\n",
    "#print(X.toarray())     \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer(smooth_idf=False)\n",
    "tfidf = transformer.fit_transform(X)\n",
    "print(tfidf.shape )                        \n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "num_clusters = 5 #Change it according to your data.\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "km.fit(tfidf)\n",
    "clusters = km.labels_.tolist()\n",
    "\n",
    "idea={'Idea':corpus, 'Cluster':clusters} #Creating dict having doc with the corresponding cluster number.\n",
    "frame=pd.DataFrame(idea,index=[clusters], columns=['Idea','Cluster']) # Converting it into a dataframe.\n",
    "\n",
    "print(\"\\n\")\n",
    "print(frame) #Print the doc with the labeled cluster number.\n",
    "print(\"\\n\")\n",
    "\n",
    "frame.to_excel(\"Output_Path\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
